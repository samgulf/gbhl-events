{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "with open('api_key.txt', 'r') as f:\n",
    "    API_KEY = f.read().strip()\n",
    "\n",
    "year = 2026\n",
    "\n",
    "# === CONFIG ===\n",
    "SHEET_ID = '1Er54lmX1jBCbjQWkcFjWX6hp0WsoTiSqeb8U9SNIReo'\n",
    "RANGE = f'{year}!A1:Z215'\n",
    "\n",
    "# === SETUP ===\n",
    "service = build('sheets', 'v4', developerKey=API_KEY)\n",
    "sheet = service.spreadsheets()\n",
    "\n",
    "# === STEP 1: Get full sheet grid with formatting ===\n",
    "result = sheet.get(\n",
    "    spreadsheetId=SHEET_ID,\n",
    "    ranges=[RANGE],\n",
    "    includeGridData=True\n",
    ").execute()\n",
    "\n",
    "grid = result['sheets'][0]['data'][0]['rowData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find all month labels (like 'JANUARY', 'FEBRUARY', etc.)\n",
    "month_positions = {}  # (row_idx, col_idx) => month_num\n",
    "month_names = {name.upper(): i for i, name in enumerate(calendar.month_name) if name}\n",
    "\n",
    "for row_idx, row in enumerate(grid):\n",
    "    for col_idx, cell in enumerate(row.get('values', [])):\n",
    "        val = cell.get('formattedValue', '')\n",
    "        val_clean = val.strip().upper()\n",
    "        if val_clean in month_names:\n",
    "            month_num = month_names[val_clean]\n",
    "            month_positions[(row_idx, col_idx)] = month_num\n",
    "\n",
    "# Step 2: For each day-number cell, find the nearest month label *above and to the right*\n",
    "date_map = {}  # (row_idx, col_idx) -> datetime\n",
    "\n",
    "for row_idx, row in enumerate(grid):\n",
    "    for col_idx, cell in enumerate(row.get('values', [])):\n",
    "        val = cell.get('formattedValue', '')\n",
    "        if not val.isdigit():\n",
    "            continue\n",
    "        day = int(val)\n",
    "\n",
    "        # Find the closest month label above and to the right\n",
    "        best_month = None\n",
    "        best_distance = float('inf')\n",
    "\n",
    "        for (m_row, m_col), month_num in month_positions.items():\n",
    "            if m_row < row_idx and m_col <= col_idx:\n",
    "                dist = (row_idx - m_row) + (col_idx - m_col)\n",
    "                if dist < best_distance:\n",
    "                    best_distance = dist\n",
    "                    best_month = month_num\n",
    "\n",
    "        if best_month is not None:\n",
    "            try:\n",
    "                date = datetime(year, best_month, day)\n",
    "                date_map[(row_idx, col_idx)] = date\n",
    "            except ValueError:\n",
    "                pass  # skip invalid dates like Feb 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "merged_ranges = result['sheets'][0].get('merges', [])\n",
    "visited = set()\n",
    "\n",
    "# Helper to find merged range for a given cell\n",
    "def get_merged_range(row, col):\n",
    "    for mr in merged_ranges:\n",
    "        if (\n",
    "            mr['startRowIndex'] <= row < mr['endRowIndex']\n",
    "            and mr['startColumnIndex'] <= col < mr['endColumnIndex']\n",
    "        ):\n",
    "            return mr\n",
    "    return None\n",
    "\n",
    "for row_idx, row in enumerate(grid):\n",
    "    for col_idx, cell in enumerate(row.get('values', [])):\n",
    "        if (row_idx, col_idx) in visited:\n",
    "            continue\n",
    "\n",
    "        val = cell.get('formattedValue')\n",
    "        if not val or val.strip().isdigit():\n",
    "            continue\n",
    "        link = cell.get('hyperlink', '')\n",
    "\n",
    "        # === Get event start date and event type color from the date cell above ===\n",
    "        event_date = None\n",
    "        event_type = 'Other'\n",
    "\n",
    "        for r2 in range(row_idx, 0, -1):\n",
    "            if (r2, col_idx) in date_map:\n",
    "                event_date = date_map[(r2, col_idx)]\n",
    "\n",
    "                # Try to read the background color from the date cell\n",
    "                try:\n",
    "                    date_cell = grid[r2]['values'][col_idx]  # <-- correct path\n",
    "                    color = date_cell.get('effectiveFormat', {}).get('backgroundColor', {})\n",
    "                    r = color.get('red', 0)\n",
    "                    g = color.get('green', 0)\n",
    "                    b = color.get('blue', 0)\n",
    "\n",
    "                    if r > 0.8 and g < 0.5:\n",
    "                        event_type = 'GBHL100'\n",
    "                    elif r > 0.8 and g > 0.8:\n",
    "                        event_type = 'GBHL90'\n",
    "                    elif b > 0.8:\n",
    "                        event_type = 'GBHL80'\n",
    "                    else:\n",
    "                        event_type = 'Other'\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to read event type color from ({r2},{col_idx}): {e}\")\n",
    "\n",
    "                break\n",
    "\n",
    "        if not event_date:\n",
    "            continue\n",
    "\n",
    "        # Parse event text\n",
    "        lines = val.strip().split('\\n')\n",
    "        if len(lines) < 3:\n",
    "            continue\n",
    "\n",
    "        event_name = lines[0].strip()\n",
    "        organizer = lines[1].strip()\n",
    "        region_loc = lines[2].strip().strip('[]')\n",
    "        region, location = region_loc.split(' - ') if ' - ' in region_loc else ('Unknown', region_loc)\n",
    "\n",
    "        # Determine merged range (if any)\n",
    "        merged = get_merged_range(row_idx, col_idx)\n",
    "        if merged:\n",
    "            end_col = merged['endColumnIndex'] - 1\n",
    "            # Mark all merged cells as visited\n",
    "            for r in range(merged['startRowIndex'], merged['endRowIndex']):\n",
    "                for c in range(merged['startColumnIndex'], merged['endColumnIndex']):\n",
    "                    visited.add((r, c))\n",
    "        else:\n",
    "            end_col = col_idx\n",
    "            visited.add((row_idx, col_idx))\n",
    "\n",
    "        # Get end date from the right-most merged cell's column\n",
    "        end_date = event_date\n",
    "        for r2 in range(row_idx, 0, -1):\n",
    "            if (r2, end_col) in date_map:\n",
    "                end_date = date_map[(r2, end_col)]\n",
    "                break\n",
    "\n",
    "        # === Extract format (Singles / Doubles) from the row below ===\n",
    "        format_type = 'Unknown'\n",
    "\n",
    "        # Determine the row below the event block\n",
    "        format_row_idx = (merged['endRowIndex'] if merged else row_idx + 1)\n",
    "\n",
    "        # Use the first column of the merged block if available, else same col\n",
    "        format_col_idx = merged['startColumnIndex'] if merged else col_idx\n",
    "\n",
    "        # Safely access the format cell\n",
    "        if format_row_idx < len(grid):\n",
    "            format_row = grid[format_row_idx]\n",
    "            if format_col_idx < len(format_row.get('values', [])):\n",
    "                format_cell = format_row['values'][format_col_idx]\n",
    "                format_val = format_cell.get('formattedValue', '').strip().lower()\n",
    "                if 'double' in format_val:\n",
    "                    format_type = 'Doubles'\n",
    "                elif 'single' in format_val:\n",
    "                    format_type = 'Singles'\n",
    "                elif 'team' in format_val:\n",
    "                    format_type = 'Team'\n",
    "                # Assume missing formats are singles events\n",
    "                else:\n",
    "                    format_type = 'Singles'\n",
    "\n",
    "        event = {\n",
    "            'start_date': event_date.strftime('%Y-%m-%d'),\n",
    "            'end_date': end_date.strftime('%Y-%m-%d'),\n",
    "            'event_name': event_name,\n",
    "            'organizer': organizer,\n",
    "            'region': region,\n",
    "            'location': location,\n",
    "            'format': format_type,\n",
    "            'event_type': event_type,\n",
    "            'link': link\n",
    "        }\n",
    "\n",
    "        events.append(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_date    end_date                event_name        organizer region  \\\n",
      "0  2026-01-02  2026-01-02           A New Adventure        Matt King     SW   \n",
      "1  2026-01-03  2026-01-04        Into The West 2026        Matt King     SW   \n",
      "2  2026-03-28  2026-03-01  Defence of North Bristol    David Clubley     SW   \n",
      "3  2026-03-28  2026-03-01    Bonds of Fellowship VI    Callum Slater     SE   \n",
      "4  2026-03-28  2026-03-01     Honour The Allegiance  Natalie Pearson  N.Eng   \n",
      "\n",
      "    location   format event_type link  \n",
      "0    Cardiff  Singles     GBHL90       \n",
      "1    Cardiff  Singles    GBHL100       \n",
      "2    Bristol  Singles     GBHL90       \n",
      "3    Havantl  Singles     GBHL90       \n",
      "4  Sheffield  Singles     GBHL90       \n"
     ]
    }
   ],
   "source": [
    "# === STEP 4: Show / Save Results ===\n",
    "df = pd.DataFrame(events)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "GBHL90     51\n",
       "GBHL80     39\n",
       "GBHL100    20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     start_date    end_date                        event_name  \\\n",
      "105  2026-10-24  2026-10-24           Great Deeds of War 2026   \n",
      "106  2026-10-25  2026-10-25           Battle for Middle Earth   \n",
      "107  2026-10-31  2026-10-01  The Crownless Shall Be King 2026   \n",
      "108  2026-11-28  2026-11-29           He Eats It By The Block   \n",
      "109  2026-11-28  2026-11-28            Grand Anglian Alliance   \n",
      "\n",
      "           organizer region      location   format event_type link  \n",
      "105   Rob Lainchbury      C    Birmingham  Singles     GBHL90       \n",
      "106    Chris Jackson     SE    Eastbourne  Singles     GBHL90       \n",
      "107     Tom Culleton     SE  High Wycombe  Singles     GBHL90       \n",
      "108  Jack Darlington      C     Leicester  Singles    GBHL100       \n",
      "109     James Palmer     SE       Woolpit  Singles     GBHL80       \n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_csv('data/gbhl_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = old_df[[\"event_name\", \"start_date\", \"lat\", \"lon\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(old_df, on=[\"event_name\", \"start_date\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual fixes on location typos\n",
    "df[\"location\"].replace(\"Abergevanny\", \"Abergavenny\", inplace=True)\n",
    "df[\"location\"].replace(\"Bedwroth\", \"Bedworth\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a location string for geocoding\n",
    "df['location_str'] = df['location'] + ', UK'\n",
    "\n",
    "# Set up Nominatim geocoder\n",
    "geolocator = Nominatim(user_agent=\"gbhl-event-locator\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)  # be polite!\n",
    "\n",
    "# Apply geocoding\n",
    "def get_coords(place):\n",
    "    try:\n",
    "        loc = geocode(place)\n",
    "        if loc:\n",
    "            return pd.Series([loc.latitude, loc.longitude])\n",
    "    except:\n",
    "        pass\n",
    "    return pd.Series([None, None])\n",
    "\n",
    "# Find rows where lat or lon is null\n",
    "missing_coords = df[df['lat'].isnull() | df['lon'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>event_name</th>\n",
       "      <th>organizer</th>\n",
       "      <th>region</th>\n",
       "      <th>location</th>\n",
       "      <th>format</th>\n",
       "      <th>event_type</th>\n",
       "      <th>link</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>location_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>2026-01-02</td>\n",
       "      <td>A New Adventure</td>\n",
       "      <td>Matt King</td>\n",
       "      <td>SW</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cardiff, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-03</td>\n",
       "      <td>2026-01-04</td>\n",
       "      <td>Into The West 2026</td>\n",
       "      <td>Matt King</td>\n",
       "      <td>SW</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL100</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cardiff, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-03-28</td>\n",
       "      <td>2026-03-01</td>\n",
       "      <td>Defence of North Bristol</td>\n",
       "      <td>David Clubley</td>\n",
       "      <td>SW</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bristol, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-03-28</td>\n",
       "      <td>2026-03-01</td>\n",
       "      <td>Bonds of Fellowship VI</td>\n",
       "      <td>Callum Slater</td>\n",
       "      <td>SE</td>\n",
       "      <td>Havantl</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Havantl, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-03-28</td>\n",
       "      <td>2026-03-01</td>\n",
       "      <td>Honour The Allegiance</td>\n",
       "      <td>Natalie Pearson</td>\n",
       "      <td>N.Eng</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sheffield, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2026-10-24</td>\n",
       "      <td>2026-10-24</td>\n",
       "      <td>Great Deeds of War 2026</td>\n",
       "      <td>Rob Lainchbury</td>\n",
       "      <td>C</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birmingham, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2026-10-25</td>\n",
       "      <td>2026-10-25</td>\n",
       "      <td>Battle for Middle Earth</td>\n",
       "      <td>Chris Jackson</td>\n",
       "      <td>SE</td>\n",
       "      <td>Eastbourne</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastbourne, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2026-10-31</td>\n",
       "      <td>2026-10-01</td>\n",
       "      <td>The Crownless Shall Be King 2026</td>\n",
       "      <td>Tom Culleton</td>\n",
       "      <td>SE</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL90</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High Wycombe, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2026-11-28</td>\n",
       "      <td>2026-11-29</td>\n",
       "      <td>He Eats It By The Block</td>\n",
       "      <td>Jack Darlington</td>\n",
       "      <td>C</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL100</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leicester, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2026-11-28</td>\n",
       "      <td>2026-11-28</td>\n",
       "      <td>Grand Anglian Alliance</td>\n",
       "      <td>James Palmer</td>\n",
       "      <td>SE</td>\n",
       "      <td>Woolpit</td>\n",
       "      <td>Singles</td>\n",
       "      <td>GBHL80</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Woolpit, UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_date    end_date                        event_name  \\\n",
       "0    2026-01-02  2026-01-02                   A New Adventure   \n",
       "1    2026-01-03  2026-01-04                Into The West 2026   \n",
       "2    2026-03-28  2026-03-01          Defence of North Bristol   \n",
       "3    2026-03-28  2026-03-01            Bonds of Fellowship VI   \n",
       "4    2026-03-28  2026-03-01             Honour The Allegiance   \n",
       "..          ...         ...                               ...   \n",
       "105  2026-10-24  2026-10-24           Great Deeds of War 2026   \n",
       "106  2026-10-25  2026-10-25           Battle for Middle Earth   \n",
       "107  2026-10-31  2026-10-01  The Crownless Shall Be King 2026   \n",
       "108  2026-11-28  2026-11-29           He Eats It By The Block   \n",
       "109  2026-11-28  2026-11-28            Grand Anglian Alliance   \n",
       "\n",
       "           organizer region      location   format event_type link  lat  lon  \\\n",
       "0          Matt King     SW       Cardiff  Singles     GBHL90       NaN  NaN   \n",
       "1          Matt King     SW       Cardiff  Singles    GBHL100       NaN  NaN   \n",
       "2      David Clubley     SW       Bristol  Singles     GBHL90       NaN  NaN   \n",
       "3      Callum Slater     SE       Havantl  Singles     GBHL90       NaN  NaN   \n",
       "4    Natalie Pearson  N.Eng     Sheffield  Singles     GBHL90       NaN  NaN   \n",
       "..               ...    ...           ...      ...        ...  ...  ...  ...   \n",
       "105   Rob Lainchbury      C    Birmingham  Singles     GBHL90       NaN  NaN   \n",
       "106    Chris Jackson     SE    Eastbourne  Singles     GBHL90       NaN  NaN   \n",
       "107     Tom Culleton     SE  High Wycombe  Singles     GBHL90       NaN  NaN   \n",
       "108  Jack Darlington      C     Leicester  Singles    GBHL100       NaN  NaN   \n",
       "109     James Palmer     SE       Woolpit  Singles     GBHL80       NaN  NaN   \n",
       "\n",
       "         location_str  \n",
       "0         Cardiff, UK  \n",
       "1         Cardiff, UK  \n",
       "2         Bristol, UK  \n",
       "3         Havantl, UK  \n",
       "4       Sheffield, UK  \n",
       "..                ...  \n",
       "105    Birmingham, UK  \n",
       "106    Eastbourne, UK  \n",
       "107  High Wycombe, UK  \n",
       "108     Leicester, UK  \n",
       "109       Woolpit, UK  \n",
       "\n",
       "[110 rows x 12 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Winchester, UK',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\http\\client.py\", line 1378, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\http\\client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\http\\client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\ssl.py\", line 1311, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 827, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 827, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Winchester%2C+UK&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Winchester%2C+UK&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Winchester%2C+UK&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('London, UK',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\http\\client.py\", line 1378, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\http\\client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\http\\client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\ssl.py\", line 1311, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 469, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 358, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 827, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 827, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London%2C+UK&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\requests\\adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London%2C+UK&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\geocoders\\nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\geocoders\\base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\samgu\\anaconda3\\envs\\py3.11\\Lib\\site-packages\\geopy\\adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=London%2C+UK&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    }
   ],
   "source": [
    "if not missing_coords.empty:\n",
    "    # Apply geocoding function just to these rows\n",
    "    missing_coords[['lat', 'lon']] = missing_coords['location_str'].apply(get_coords)\n",
    "\n",
    "    # Update the original dataframe only for those indices\n",
    "    df.loc[missing_coords.index, ['lat', 'lon']] = missing_coords[['lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_event_duration(start_str, end_str):\n",
    "    start_date = datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end_date = datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    start_dow = start_date.weekday()  # 0=Monday ... 5=Saturday ... 6=Sunday\n",
    "    end_dow = end_date.weekday()\n",
    "\n",
    "    if start_dow == 5 and end_dow == 5:\n",
    "        return \"Saturday\"\n",
    "    elif start_dow == 6 and end_dow == 6:\n",
    "        return \"Sunday\"\n",
    "    elif start_dow == 5 and end_dow == 6:\n",
    "        return \"Weekend\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply to dataframe\n",
    "df['event_duration'] = df.apply(\n",
    "    lambda row: classify_event_duration(row['start_date'], row['end_date']),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/gbhl_events.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/events.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
